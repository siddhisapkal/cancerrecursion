# -*- coding: utf-8 -*-
"""ML_OEA_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/136Npar7eDgUcqDQxxHEpY61q58UB8EH2
"""

# Step 1: Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder, StandardScaler


# Step 2: Load the data
df = pd.read_csv("/content/filtered_thyroid_data.csv")

# Step 3: Encode categorical features
le = LabelEncoder()
for column in df.columns:
    if df[column].dtype == 'object':
        df[column] = le.fit_transform(df[column])

# Step 4: Define features and target
X = df.drop("Recurred", axis=1)
y = df["Recurred"]

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Scale the data using StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 7: Train Logistic Regression model with increased max_iter to avoid convergence warning
model_lr = LogisticRegression(max_iter=500, random_state=42)
model_lr.fit(X_train_scaled, y_train)

# Step 8: Evaluate the model
y_pred = model_lr.predict(X_test_scaled)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))



from google.colab import drive
drive.mount('/content/drive')

# Step 1: Import libraries
from sklearn.naive_bayes import GaussianNB
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score


# Step 2: Load the data
df = pd.read_csv("/content/filtered_thyroid_data.csv")

# Step 3: Encode categorical features
le = LabelEncoder()
for column in df.columns:
    if df[column].dtype == 'object':
        df[column] = le.fit_transform(df[column])

# Step 4: Define features and target
X = df.drop("Recurred", axis=1)
y = df["Recurred"]

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Train Naive Bayes model
model_nb = GaussianNB()
model_nb.fit(X_train, y_train)

# Step 7: Evaluate the model
y_pred = model_nb.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer

# Assuming df is already loaded

# -------------------------------
# Encoding T, N, M columns
# -------------------------------
def encode_cancer_stage(stage):
    if isinstance(stage, str):  # Check if the value is a string (e.g., T1a)
        if 'T' in stage:
            return int(stage[1])  # Extracting numeric part after 'T'
        elif 'N' in stage:
            return int(stage[1])  # Extracting numeric part after 'N'
        elif 'M' in stage:
            return int(stage[1])  # Extracting numeric part after 'M'
    return stage  # If it's already a number, return it as is

# Apply encoding to T, N, M
df['T'] = df['T'].apply(encode_cancer_stage)
df['N'] = df['N'].apply(encode_cancer_stage)
df['M'] = df['M'].apply(encode_cancer_stage)

# -------------------------------
# Label Encoding for categorical columns
# -------------------------------
le = LabelEncoder()

# Encode Gender, Risk, Response columns
df['Gender'] = le.fit_transform(df['Gender'])
df['Risk'] = le.fit_transform(df['Risk'])
df['Response'] = le.fit_transform(df['Response'])

# Create combined TNM_Score
df['TNM_Score'] = df['T'] + df['N'] + df['M']
# -------------------------------
# Handle Missing Values
# -------------------------------
# Impute missing values for TNM_Score column if necessary
imputer = SimpleImputer(strategy='median')  # You can use mean or median depending on context
df[['TNM_Score']] = imputer.fit_transform(df[['TNM_Score']])

# -------------------------------
# Visualizations & Model Preparation
# -------------------------------
# Let's prepare the data for machine learning
X = df.drop(columns=["Recurred", "T", "N", "M"])
y = df["Recurred"]

# Now X and y are ready for model training, split into training and testing sets as required

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

# Sample data (replace with your actual dataframe)
df = pd.DataFrame({
    'Gender': ['Female', 'Male', 'Female', 'Male', 'Female', 'Male'],
    'Recurred': ['No', 'Yes', 'Yes', 'No', 'No', 'Yes']
})

# Initialize LabelEncoder
le = LabelEncoder()

# Transform categorical variables into numeric values
df['Gender'] = le.fit_transform(df['Gender'])  # Female=0, Male=1
df['Recurred'] = le.fit_transform(df['Recurred'])  # No=0, Yes=1

# Plot Gender vs Recurred with different colors for 'Yes' and 'No'
sns.countplot(x='Gender', hue='Recurred', data=df, palette={0: 'blue', 1: 'green'})

# Customizing the plot
plt.title('Gender vs Recurred')
plt.xticks([0, 1], ['Female', 'Male'])
plt.legend(title='Recurred', labels=['No', 'Yes'])
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv("filtered_thyroid_data.csv")

# Plot boxplot: Age vs. Recurrence
plt.figure(figsize=(8, 6))
sns.boxplot(data=df, x='Recurred', y='Age', hue='Recurred', palette='pastel', dodge=False, legend=False)

plt.title("Age Distribution by Recurrence")
plt.xlabel("Recurrence")
plt.ylabel("Age")
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("filtered_thyroid_data.csv")

# Create a bar chart: count of recurrence (Yes/No) by Stage
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='Stage', hue='Recurred', palette='Set2')

plt.title("Thyroid Cancer Recurrence by Stage")
plt.xlabel("Cancer Stage")
plt.ylabel("Number of Patients")
plt.legend(title="Recurrence")
plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# -------------------------------
# Train-Test Split
# -------------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# -------------------------------
# Hyperparameter Tuning (GridSearchCV)
# -------------------------------
params = {
    'max_depth': [3],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy'],
    'class_weight': ['balanced', None]
}

# Initialize a DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)

# Apply GridSearchCV for hyperparameter tuning
grid = GridSearchCV(dt, param_grid=params, cv=2, scoring='accuracy')
grid.fit(X_train, y_train)

# -------------------------------
# Model Evaluation
# -------------------------------
# Get the best model from GridSearchCV
best_model = grid.best_estimator_

# Predict using the best model
y_pred = best_model.predict(X_test)

# Accuracy and Classification Report
print("Best Parameters:", grid.best_params_)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix Visualization
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# -------------------------------
# Decision Tree Visualization
# -------------------------------
plt.figure(figsize=(15, 10))
plot_tree(best_model, filled=True, feature_names=X.columns, class_names=['No Recurred', 'Recurred'], fontsize=10)
plt.title('Decision Tree Visualization')
plt.show()

df.head()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

# Define your classification report manually (since we already have the values)
report_data = {
    "Class": ["0 (No)", "1 (Yes)", "Accuracy", "Macro Avg", "Weighted Avg"],
    "Precision": [0.97, 1.00, "", 0.98, 0.97],
    "Recall":    [1.00, 0.89, "", 0.95, 0.97],
    "F1-Score":  [0.98, 0.94, 0.97, 0.96, 0.97],
    "Support":   [58, 19, 77, 77, 77]
}

# Create a DataFrame
df_report = pd.DataFrame(report_data)

# Plotting the table using matplotlib
fig, ax = plt.subplots(figsize=(8, 3))
ax.axis('off')
table = ax.table(cellText=df_report.values, colLabels=df_report.columns, loc='center', cellLoc='center')
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1.2, 1.5)

# Title
plt.title("Classification Report", fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

df.head()
